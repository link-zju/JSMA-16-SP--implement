{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial python library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSMA method\n",
    "class JSMA():\n",
    "    def __init__(self, width, height, channel, cmin, cmax, n_class) -> None:\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.channel = channel\n",
    "        self.input_size = width * height * channel\n",
    "        self.cmin = cmin\n",
    "        self.cmax = cmax\n",
    "        self.n_class = n_class\n",
    "\n",
    "\n",
    "    def saliency_map(self, phi, dtdx, dodx):\n",
    "        \"\"\"\n",
    "        Saliency map function that returns score for each input dimension.\n",
    "        Algorithm 3 Increasing pixel intensities saliency map\n",
    "        \"\"\"\n",
    "        _max = 0\n",
    "        \n",
    "        for pixel_pair in phi:\n",
    "            _alpha = torch.sum(dtdx[pixel_pair[0,0], pixel_pair[0,1], :] + dtdx[pixel_pair[1,0], pixel_pair[1,1], :])\n",
    "            if _alpha <= 0:\n",
    "                continue\n",
    "\n",
    "            _beta = torch.sum(dodx[pixel_pair[0,0], pixel_pair[0,1], :] + dodx[pixel_pair[1,0], pixel_pair[1,1], :])\n",
    "            if _beta >= 0:\n",
    "                continue\n",
    "\n",
    "            if (-_alpha * _beta > _max): \n",
    "                selected_pixel_pair = pixel_pair\n",
    "                _max = -_alpha * _beta\n",
    "\n",
    "        return selected_pixel_pair\n",
    "\n",
    "\n",
    "    def jacobian_matrix(self, my_nn_model, x, n_class):\n",
    "        \"\"\"\n",
    "        Calculate jacobian of logits wrt input.\n",
    "        \"\"\"\n",
    "        inp = x.detach().clone()\n",
    "        Jn = torch.zeros((self.width, self.height, n_class))  # loop will fill in Jacobian\n",
    "        Jn = Jn.float()\n",
    "\n",
    "        inp.requires_grad_()\n",
    "\n",
    "        preds = my_nn_model(inp)\n",
    "        for i in range(n_class):\n",
    "            grd = torch.zeros((1, n_class)).cuda()  # same shape as preds\n",
    "            grd[0, i] = 1  # column of Jacobian to compute\n",
    "            preds.backward(gradient=grd, retain_graph=True)\n",
    "            Jn[:, :, i] = inp.grad.float()  # fill in one column of Jacobian\n",
    "            inp.grad.zero_()  # .backward() accumulates gradients, so reset to zero\n",
    "\n",
    "        return Jn\n",
    "\n",
    "\n",
    "    def jsma(self, phi, X_adv, target_y, model, eps, cmin=0.0, cmax=1.0):\n",
    "        \"\"\"\n",
    "        Implementation of JSMA method to generate adversarial images.\n",
    "        \"\"\"\n",
    "        # Get model logits and probs for the input.\n",
    "        # logits, probs = model(torch.reshape(X_adv, shape=(-1, self.width, self.height, self.channel)))\n",
    "        probs = model(X_adv)\n",
    "        \n",
    "        # Get model prediction for inputs.\n",
    "        y_ind = torch.argmax(probs[0])\n",
    "        print(probs[0])\n",
    "        \n",
    "        import time;start = time.time()\n",
    "        # Calculate jacobian matrix of logits wrt to input.\n",
    "        jacobian = self.jacobian_matrix(model, X_adv, self.n_class)\n",
    "        end = time.time();print(\"Calculate jacobian matrix of logits wrt to input {}\".format(end - start))\n",
    "        \n",
    "        grad_target = jacobian[:, :, target_y]\n",
    "        \n",
    "        mask_grad_other = torch.ones(self.n_class)\n",
    "        mask_grad_other[grad_target.long()] = 0\n",
    "        grad_other = jacobian[:, :, mask_grad_other==1]\n",
    "        \n",
    "        start = time.time()\n",
    "        pixel_pair = self.saliency_map(phi, grad_target, grad_other)\n",
    "        print(pixel_pair)\n",
    "        end = time.time();print(\"Compute saliency score for each dimension {}\".format(end - start))\n",
    "\n",
    "        # perturb the input image X\n",
    "        X_adv[0, 0, pixel_pair[0,0], pixel_pair[0,1]] += eps\n",
    "        X_adv[0, 0, pixel_pair[1,0], pixel_pair[1,1]] += eps\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # remove the pixel pair whose values are out of the [cmin, cmax]\n",
    "        update_phi = []\n",
    "        c1 = (eps < 0 and X_adv[0, 0, pixel_pair[0,0], pixel_pair[0,1]] <= cmin) or (eps > 0 and X_adv[0, 0, pixel_pair[0,0], pixel_pair[0,1]] >= cmax)\n",
    "        c2 =(eps < 0 and X_adv[0, 0, pixel_pair[1,0], pixel_pair[1,1]] <= cmin) or (eps > 0 and X_adv[0, 0, pixel_pair[1,0], pixel_pair[1,1]] >= cmax)\n",
    "        if c1 and c2:\n",
    "            for _item in phi:\n",
    "                if torch.equal(pixel_pair[0], _item[0]) or torch.equal(pixel_pair[0], _item[1]):\n",
    "                    continue\n",
    "                if torch.equal(pixel_pair[1], _item[0]) or torch.equal(pixel_pair[1], _item[1]):\n",
    "                    continue\n",
    "                update_phi.append(_item)\n",
    "            phi = update_phi\n",
    "            phi = torch.stack(phi)\n",
    "                    \n",
    "        elif c1:\n",
    "            for _item in phi:\n",
    "                if torch.equal(pixel_pair[0], _item[0]) or torch.equal(pixel_pair[0], _item[1]):\n",
    "                    continue\n",
    "                update_phi.append(_item)\n",
    "            phi = update_phi\n",
    "            phi = torch.stack(phi)\n",
    "\n",
    "        elif c2:\n",
    "            for _item in phi:\n",
    "                if torch.equal(pixel_pair[1], _item[0]) or torch.equal(pixel_pair[1], _item[1]):\n",
    "                    continue\n",
    "                update_phi.append(_item)\n",
    "            phi = update_phi\n",
    "            phi = torch.stack(phi)\n",
    "\n",
    "        else:\n",
    "            pass  # no pixel pair needs to be removed \n",
    "        \n",
    "        end = time.time();print(\"update_phi {}\".format(end - start))\n",
    "\n",
    "        X_adv = torch.clamp(X_adv, cmin, cmax)\n",
    "        print(X_adv[0, 0, pixel_pair[0,0], pixel_pair[0,1]])\n",
    "        print(X_adv[0, 0, pixel_pair[1,0], pixel_pair[1,1]])\n",
    "\n",
    "        return X_adv, y_ind, phi\n",
    "\n",
    "    def generate_jsma(self, model, X, target, eps=1.0/255, epochs=50):\n",
    "        \"\"\"\n",
    "        Run JSMA on input image for `epochs` number of times.\n",
    "        \"\"\"\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        probs = model(X)\n",
    "        y_ind = torch.argmax(probs[0])\n",
    "        pert_X = X.clone()\n",
    "\n",
    "        # generate the initial pixel pair set\n",
    "        temp_phi = []\n",
    "        phi = []\n",
    "        for i in range(self.width):\n",
    "            for j in range(self.height):\n",
    "                temp_phi.append([i, j])\n",
    "        \n",
    "        for i_phi in temp_phi:\n",
    "            for j_phi in temp_phi:\n",
    "                if i_phi != j_phi:\n",
    "                    phi.append([i_phi, j_phi])\n",
    "        \n",
    "        len_temp_phi = len(temp_phi) * (len(temp_phi)-1)\n",
    "        \n",
    "        phi = phi[:int(len_temp_phi/2)]\n",
    "        phi = torch.Tensor(phi).long()\n",
    "\n",
    "        # Op for one iteration of jsma.\n",
    "        _epoch = 0\n",
    "        while not (_epoch >= epochs or y_ind == target or phi == []):\n",
    "            pert_X, y_ind, phi = self.jsma(phi, pert_X, target_y=target, model=model, eps=eps)\n",
    "            print(\"generate_jsma epochs: {}\".format(_epoch))\n",
    "            _epoch+=1\n",
    "    \n",
    "        pert = pert_X - X\n",
    "            \n",
    "        return pert_X.reshape(-1, self.width, self.height, self.channel), pert.reshape(-1, self.width, self.height, self.channel), phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "class CNN_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, padding=1, padding_mode='zeros')\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, padding=1, padding_mode='zeros')\n",
    "        self.fc1 = nn.Linear(7 * 7 * 16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load torch pre-trained MNIST model and dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "batch_size = 64\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select an image of training set with label 1\n",
    "print(train_data[3][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train or load the existing the CNN model\n",
    "PATH = './mnist_net.pth'\n",
    "net = CNN_model().cuda()\n",
    "if os.path.exists(PATH):\n",
    "    net.load_state_dict(torch.load(PATH))   \n",
    "    print('Finished loading') \n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    for epoch in range(1000):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 20:.3f}')\n",
    "                running_loss = 0.0\n",
    "    \n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test overall accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy for each class\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch JSMA attack on CNN model\n",
    "# init hyper-parameter\n",
    "width = 28\n",
    "height = 28\n",
    "channel = 1\n",
    "cmin = 0.0\n",
    "cmax = 1.0\n",
    "n_class = 10\n",
    "\n",
    "# the images with label 1\n",
    "images = torch.Tensor(train_data[3][0][None]).cuda()\n",
    "\n",
    "# the targeted label of perturbation\n",
    "target = torch.Tensor([7]).long().cuda()\n",
    "print(\"Original label: {}\".format(train_data[3][1]))\n",
    "print(\"Targeted label: {}\".format(target))\n",
    "\n",
    "jsma_attack = JSMA(width, height, channel, cmin, cmax, n_class)\n",
    "\n",
    "# the epsilon > 0\n",
    "pert_X, pert, phi = jsma_attack.generate_jsma(net, images, target, eps=1./255, epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the perturbed image\n",
    "imshow(pert_X[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the perturbation\n",
    "imshow(pert[0].cpu())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fbe8f6fe52f641a2794353dc044291527d2f768b4517fdbb4e36c55900a90e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('rl-baseline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
